# -*- coding: utf-8 -*-
"""NearMiss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QDfeADFlU7iZgv861zPdeZBhvtEy2bZ_
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import roc_auc_score,matthews_corrcoef
import numpy as np
from imblearn.under_sampling import NearMiss
import tensorflow as tf
from tensorflow import keras

from sklearn.model_selection import cross_val_predict
from sklearn.naive_bayes import GaussianNB
#import joblib
from sklearn.metrics import (f1_score, roc_auc_score,confusion_matrix, accuracy_score,
                             precision_score, recall_score)
from sklearn.tree import DecisionTreeClassifier

df = pd.read_csv("/content/drive/MyDrive/dataset/dataset_final.csv")

df.head()

df.shape

df.drop('Unnamed: 0',axis=1,inplace=True)

df.shape

X=df.drop(["fraud_bool"],axis=1)
Y=df["fraud_bool"]
#x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=42,stratify=Y)

nm = NearMiss()
x_sample, y_sample= nm.fit_resample(X,Y)
print(y_sample.value_counts())

#count_class_0, count_class_1 = df.fraud_bool.value_counts()

# Divide by class
#df_class_0 = df[df['fraud_bool'] == 0]
#df_class_1 = df[df['fraud_bool'] == 1]

#df_class_0_under = df_class_0.sample((count_class_1),random_state=42)
#df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)

#print('Random under-sampling:')
#print(df_test_under.fraud_bool.value_counts())

#x = df_test_under.drop('fraud_bool',axis='columns')
#y = df_test_under['fraud_bool']

x_train_sample, x_test_sample, y_train_sample, y_test_sample = train_test_split(x_sample, y_sample, test_size=0.2,random_state=42,stratify=y_sample)

print(x_train_sample.shape)
print(x_test_sample.shape)

#weights_assigned={0:1,1:100}

n_inputs=(len(x_train_sample.columns))

model = keras.Sequential()
model.add(keras.layers.BatchNormalization(input_shape=[x_train_sample.shape[1]]))
model.add(keras.layers.Dense(512,input_dim=n_inputs,activation='relu',kernel_initializer='he_uniform'))#128
#kernal_initializer='he_uniform' ---> weight initializer for relu 
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Dense(128,activation='relu'))#64
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Dense(64,activation='relu'))#64
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Dense(64,activation='relu'))
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Dense(32,activation='relu'))
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Dense(1,activation='sigmoid'))


model.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.007))
model.fit(x_train_sample,y_train_sample,epochs=100,batch_size=1032)#,class_weight=weights_assigned

#joblib.dump(model,'/content/drive/MyDrive/ANN_02.joblib')

import pickle

#pickle.dump(model, open('model_ANN.pkl', 'wb'))

y_pred=model.predict(x_test_sample)

print(roc_auc_score(y_test_sample,y_pred))

y_pred01=np.round(y_pred)
y_pred01=y_pred01.astype(int)
print(classification_report(y_test_sample, y_pred01))
print(confusion_matrix(y_test_sample,y_pred01))

mcc=matthews_corrcoef(y_test_sample,y_pred01)
print(mcc)

